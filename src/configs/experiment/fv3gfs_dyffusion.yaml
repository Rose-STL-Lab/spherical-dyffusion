# @package _global_

# to execute this experiment run:
# python run.py experiment=fv3gfs_dyffusion

# Important:
# 1. This experiment requires the interpolator to be trained first.
#   The interpolator run id should be set in the `diffusion.interpolator_run_id` field below.
# 2. After training, try running inference with each of the checkpoints saved. Sometimes earlier checkpoints perform better.

defaults:
  - fv3gfs.yaml
  - override /module: forecasting_multi_horizon_dyffusion.yaml
  - override /diffusion: dyffusion.yaml
  - _self_

name: "FV3GFS-DY-${datamodule.horizon}h"

datamodule:
  horizon: 6
  prediction_horizon: 504        # validation loader 1
  prediction_horizon_long: 1464  # validation loader 2 (every inference_val_every_n_epochs epochs)

module:
  enable_inference_dropout: False
  inference_val_every_n_epochs: 10  # go for prediction_horizon_long steps every 10 epochs

diffusion:
  interpolator_run_id: ???  # Read off the Weights & Biases ID from the interpolator run
  # Which checkpoint to use from the interpolator run:
  interpolator_wandb_ckpt_filename: "last.ckpt"  # "best-val_avg_crps.ckpt"

callbacks:
  model_checkpoint_time_mean_rmse_air_temperature_7:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/time_mean/rmse/air_temperature_7"   # name of the logged metric which determines when model is improving
    mode: "min"         # "max" means higher metric value is better, can be also "min"
    save_top_k: 1               # save k best models (determined by above metric)
    save_last: False            # already saved in normal model checkpoint
    verbose: ${verbose}
    dirpath: ${ckpt_dir}
    filename: "${name}_${name_suffix}_epoch{epoch:03d}_seed${seed}"
    auto_insert_metric_name: False
  model_checkpoint_time_mean_rmse_pressure:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/time_mean/rmse/PRESsfc"   # name of the logged metric which determines when model is improving
    mode: "min"         # "max" means higher metric value is better, can be also "min"
    save_top_k: 1               # save k best models (determined by above metric)
    save_last: False            # already saved in normal model checkpoint
    verbose: ${verbose}
    dirpath: ${ckpt_dir}
    filename: "${name}_${name_suffix}_epoch{epoch:03d}_seed${seed}"
    auto_insert_metric_name: False

logger:
  wandb:
    tags: ["fv3gfs", "dyffusion"]